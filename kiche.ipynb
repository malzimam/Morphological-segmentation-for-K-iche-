{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.preprocessing import OneHotEncoder\n",
    "from scipy.sparse import hstack\n",
    "from scipy.sparse import coo_matrix\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import classification_report\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.model_selection import StratifiedKFold\n",
    "import matplotlib.pyplot as plt\n",
    "import re"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "dat = pd.read_csv(\"kiche/TRAIN.tsv\", sep=\"\\t\", encoding=\"UTF-8\", header=None)\n",
    "dev = pd.read_csv(\"kiche/DEV.tsv\", sep=\"\\t\", encoding=\"UTF-8\", header=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Ri numam xkamik are taq kʼo jumuchʼ lajuj ujun...</td>\n",
       "      <td>Ri nu&gt;mam x&gt;kamik are taq kʼo jumuchʼ lajuj u&gt;...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Nojel qʼij ri a Tiʼx kuyuqʼuj le taq awaj jela...</td>\n",
       "      <td>Nojel qʼij ri a Tiʼx k&gt;u&gt;yuqʼuj le taq awaj je...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Kateʼbʼin .</td>\n",
       "      <td>K&gt;at&gt;eʼ&gt;bʼin .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Entonses are kʼwaʼ le kawaj kinbʼij pan in .</td>\n",
       "      <td>Entonses are kʼ&gt;waʼ le k&gt;aw&gt;aj k&gt;in&gt;bʼij pan in .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Nim raqan le cheʼ .</td>\n",
       "      <td>Nim r&gt;aqan le cheʼ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Chweʼq kinchakun pa qʼij chi chaqʼabʼ .</td>\n",
       "      <td>Chweʼq k&gt;in&gt;chakun pa qʼij chi chaqʼabʼ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Jeʼ , kimbʼek .</td>\n",
       "      <td>Jeʼ , k&gt;im&gt;bʼe&gt;k .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Ri imul xuchʼij taj , xkanaj pa bʼe , rumal ri...</td>\n",
       "      <td>Ri imul x&gt;u&gt;chʼij taj , x&gt;kanaj pa bʼe , r&gt;uma...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Ri ukis akʼ utz kyaʼik chi uxeʼ ri tikoʼn .</td>\n",
       "      <td>Ri u&gt;kis akʼ utz k&gt;yaʼ&gt;ik chi u&gt;xeʼ ri tikoʼn .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Chweʼq kinbʼe pa nim tinamit .</td>\n",
       "      <td>Chweʼq k&gt;in&gt;bʼe pa nim tinamit .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                   0  \\\n",
       "0  Ri numam xkamik are taq kʼo jumuchʼ lajuj ujun...   \n",
       "1  Nojel qʼij ri a Tiʼx kuyuqʼuj le taq awaj jela...   \n",
       "2                                        Kateʼbʼin .   \n",
       "3       Entonses are kʼwaʼ le kawaj kinbʼij pan in .   \n",
       "4                                Nim raqan le cheʼ .   \n",
       "5            Chweʼq kinchakun pa qʼij chi chaqʼabʼ .   \n",
       "6                                    Jeʼ , kimbʼek .   \n",
       "7  Ri imul xuchʼij taj , xkanaj pa bʼe , rumal ri...   \n",
       "8        Ri ukis akʼ utz kyaʼik chi uxeʼ ri tikoʼn .   \n",
       "9                     Chweʼq kinbʼe pa nim tinamit .   \n",
       "\n",
       "                                                   1  \n",
       "0  Ri nu>mam x>kamik are taq kʼo jumuchʼ lajuj u>...  \n",
       "1  Nojel qʼij ri a Tiʼx k>u>yuqʼuj le taq awaj je...  \n",
       "2                                     K>at>eʼ>bʼin .  \n",
       "3  Entonses are kʼ>waʼ le k>aw>aj k>in>bʼij pan in .  \n",
       "4                               Nim r>aqan le cheʼ .  \n",
       "5          Chweʼq k>in>chakun pa qʼij chi chaqʼabʼ .  \n",
       "6                                 Jeʼ , k>im>bʼe>k .  \n",
       "7  Ri imul x>u>chʼij taj , x>kanaj pa bʼe , r>uma...  \n",
       "8    Ri u>kis akʼ utz k>yaʼ>ik chi u>xeʼ ri tikoʼn .  \n",
       "9                   Chweʼq k>in>bʼe pa nim tinamit .  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dat.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 305,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Chi uxeʼ ri mexa kʼo wi ri chʼo .</td>\n",
       "      <td>Chi u&gt;xeʼ ri mexa kʼo wi ri chʼo .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Na xinnabʼej ta chutasik qakʼolibʼal .</td>\n",
       "      <td>Na x&gt;in&gt;nabʼej ta ch&gt;u&gt;tas&gt;ik qa&gt;kʼolibʼal .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Xubʼij che : - jas xabʼano Tintin ?</td>\n",
       "      <td>X&gt;u&gt;bʼij ch&gt;e : - jas x&gt;a&gt;bʼan&gt;o Tintin ?</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Chanim in kʼo pa mokokil .</td>\n",
       "      <td>Chanim in kʼo pa mokokil .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Xalax pa ri Kaweq .</td>\n",
       "      <td>X&gt;alax pa ri Kaweq .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Xpax ri ujukubʼ , ri kej .</td>\n",
       "      <td>X&gt;pax ri u&gt;jukubʼ , ri kej .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Je la leʼ ri nupwiʼ .</td>\n",
       "      <td>Je la leʼ ri nu&gt;pwiʼ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>Kʼo pa ja tijobʼal ri wikaqʼ .</td>\n",
       "      <td>Kʼo pa ja tijobʼal ri w&gt;ikaqʼ .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>Xinalax pa jun qʼij ubʼiʼ wajxaqibʼ Noʼj .</td>\n",
       "      <td>X&gt;in&gt;alax pa jun qʼij u&gt;bʼiʼ wajxaqibʼ Noʼj .</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>Aʼre xetoʼw alaq .</td>\n",
       "      <td>Aʼre x&gt;e&gt;toʼ&gt;w alaq .</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                            0  \\\n",
       "0           Chi uxeʼ ri mexa kʼo wi ri chʼo .   \n",
       "1      Na xinnabʼej ta chutasik qakʼolibʼal .   \n",
       "2         Xubʼij che : - jas xabʼano Tintin ?   \n",
       "3                  Chanim in kʼo pa mokokil .   \n",
       "4                         Xalax pa ri Kaweq .   \n",
       "5                  Xpax ri ujukubʼ , ri kej .   \n",
       "6                       Je la leʼ ri nupwiʼ .   \n",
       "7              Kʼo pa ja tijobʼal ri wikaqʼ .   \n",
       "8  Xinalax pa jun qʼij ubʼiʼ wajxaqibʼ Noʼj .   \n",
       "9                          Aʼre xetoʼw alaq .   \n",
       "\n",
       "                                               1  \n",
       "0             Chi u>xeʼ ri mexa kʼo wi ri chʼo .  \n",
       "1   Na x>in>nabʼej ta ch>u>tas>ik qa>kʼolibʼal .  \n",
       "2      X>u>bʼij ch>e : - jas x>a>bʼan>o Tintin ?  \n",
       "3                     Chanim in kʼo pa mokokil .  \n",
       "4                           X>alax pa ri Kaweq .  \n",
       "5                   X>pax ri u>jukubʼ , ri kej .  \n",
       "6                         Je la leʼ ri nu>pwiʼ .  \n",
       "7                Kʼo pa ja tijobʼal ri w>ikaqʼ .  \n",
       "8  X>in>alax pa jun qʼij u>bʼiʼ wajxaqibʼ Noʼj .  \n",
       "9                          Aʼre x>e>toʼ>w alaq .  "
      ]
     },
     "execution_count": 305,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dev.head(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tokenizer(inp: object):\n",
    "    \"\"\"tokenize a pandas column of strings and add begnning and end markers\n",
    "    :param inp: pandas column\n",
    "    \n",
    "    >>>tokenizer(df[\"foo\"])\n",
    "    [[\"^foo$\", \"^bar$\"], [\"^baz$\"]]\n",
    "    \"\"\"\n",
    "    words = [(\"^\" + i + \"$\") for i in inp]\n",
    "    for i in range(len(words)):\n",
    "        words[i] = re.sub(\" \", \"$ ^\", words[i])\n",
    "        words[i] = words[i].split(' ')\n",
    "    return words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess(inp: list):\n",
    "    \"\"\"turns list of lists of lexeme strings into a list of lists of lists of phoneme feature dictionaries\n",
    "    :param inp: list to process\n",
    "    \n",
    "    >>> preprocess([[\"^abc$\"]])\n",
    "    \"\"\"\n",
    "    try:\n",
    "        assert type(inp) == list\n",
    "        assert type(inp[0]) == list\n",
    "        assert type(inp[0][0]) == str\n",
    "        assert inp[0][0][0]\n",
    "        assert type(inp[0][0][0]) == str\n",
    "    except:\n",
    "        raise TypeError(\"input needs to be a list of lists of strings\")\n",
    "    stats = []\n",
    "    vowels = {\"u\", \"i\", \"a\", \"o\", \"e\", \"ʼ\"}\n",
    "    velar = {\"k\", \"x\", \"q\"}\n",
    "    for sent in inp:\n",
    "        snt = []\n",
    "        for index in range(len(sent)):\n",
    "            word = sent[index]\n",
    "            true_len = len(word) - 2\n",
    "            if true_len <= 1:\n",
    "                continue\n",
    "            wrd = []\n",
    "            for i in range(len(word))[1:true_len]:\n",
    "                dic = {}\n",
    "                dic[\"beg\"]=i\n",
    "                dic[\"sym\"]=word[i]\n",
    "                if dic[\"sym\"] in vowels:\n",
    "                    dic[\"vow\"] = 1\n",
    "                else:\n",
    "                    dic[\"vow\"] = 0\n",
    "                if dic[\"sym\"] in velar:\n",
    "                    dic[\"vel\"] = 1\n",
    "                else:\n",
    "                    dic[\"vel\"] = 0\n",
    "                dic[\"pos\"] = index\n",
    "                dic[\"end\"]=true_len - dic[\"beg\"]\n",
    "                dic[\"len\"]=true_len\n",
    "                dic[\"mult\"]=np.log1p(dic[\"beg\"] * dic[\"end\"])\n",
    "                dic[\"add\"]=dic[\"len\"] / dic[\"mult\"]\n",
    "                dic[\"relBeg\"]=dic[\"beg\"] / dic[\"len\"]\n",
    "                dic[\"relEnd\"]=dic[\"end\"] / dic[\"len\"]\n",
    "                dic[\"logBeg\"]=np.log1p(dic[\"relBeg\"])\n",
    "                dic[\"logEnd\"]=np.log1p(dic[\"relEnd\"])\n",
    "                dic[\"prev\"]=word[i-1]\n",
    "                if dic[\"prev\"] in vowels:\n",
    "                    dic[\"prevV\"] = 1\n",
    "                else:\n",
    "                    dic[\"prevV\"] = 0\n",
    "                dic[\"next\"]=word[i+1]\n",
    "                if dic[\"next\"] in vowels:\n",
    "                    dic[\"nextV\"] = 1\n",
    "                else:\n",
    "                    dic[\"nextV\"] = 0\n",
    "                dic[\"next2\"]=word[i+2]\n",
    "                dic[\"nextBi\"]=dic[\"next\"] + dic[\"next2\"]\n",
    "                dic[\"prevBi\"]=dic[\"prev\"] + dic[\"sym\"]\n",
    "                dic[\"curBi\"]=dic[\"sym\"] + dic[\"next\"]\n",
    "                dic[\"prevTri\"]=dic[\"prev\"] + dic[\"curBi\"]\n",
    "                dic[\"curTri\"]=dic[\"sym\"] + dic[\"nextBi\"]\n",
    "                if \"$\" in dic[\"nextBi\"]:\n",
    "                    dic[\"nextTri\"]=dic[\"nextBi\"]+\"$\"\n",
    "                else:\n",
    "                    dic[\"nextTri\"]=dic[\"nextBi\"]+word[i+3]\n",
    "                dic[\"curQuat\"]=dic[\"prev\"] + dic[\"curTri\"]\n",
    "                wrd.append(dic)\n",
    "            snt.append(wrd)\n",
    "        stats.append(snt)\n",
    "    return stats"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "words_1 = tokenizer(dat.iloc[:,0])\n",
    "tst = tokenizer(dev.iloc[:,0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "tst_stats = preprocess(tst)\n",
    "sym_stats = preprocess(words_1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "def tyndices(inp: str):\n",
    "    tyndex = 0\n",
    "    ret = set()\n",
    "    for i in range(len(inp)):\n",
    "        if inp[i] == \">\":\n",
    "            ret.add(tyndex - 1)\n",
    "        else:\n",
    "            tyndex += 1\n",
    "    return ret"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "def sent_process(inp: list, ind: int):\n",
    "    tynd = 0\n",
    "    for word_ind in range(len(inp)):\n",
    "        wrd = inp[word_ind][:-1]\n",
    "#         wrd = inp[word_ind]\n",
    "        if len(wrd) == 0:\n",
    "            continue\n",
    "        hlp = tyndices(wrd)\n",
    "#         print(tynd)\n",
    "#         print(len(sym_stats[ind]))\n",
    "#         print(sym_stats[ind][tynd])\n",
    "        appendix(sym_stats[ind][tynd], hlp)\n",
    "        tynd += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "def appendix(inp: list, tynd: set):\n",
    "    for index in range(len(inp)):\n",
    "        if index in tynd:\n",
    "            inp[index][\"bound\"] = 1\n",
    "        else:\n",
    "            inp[index][\"bound\"] = 0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_sound_list(inp: list): \n",
    "    all_sents = []\n",
    "    for i in inp:\n",
    "        all_sents += i\n",
    "    all_words = []\n",
    "    for i in all_sents:\n",
    "        all_words += i\n",
    "    return all_words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "words2 = [i.split(\" \") for i in dat.iloc[:,1]]\n",
    "for ind, sent in enumerate(words2):\n",
    "    sent_process(sent, ind)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "neues = pd.DataFrame.from_dict(to_sound_list(sym_stats))\n",
    "all_tst = pd.DataFrame.from_dict(to_sound_list(tst_stats))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beg</th>\n",
       "      <th>sym</th>\n",
       "      <th>vow</th>\n",
       "      <th>vel</th>\n",
       "      <th>pos</th>\n",
       "      <th>end</th>\n",
       "      <th>len</th>\n",
       "      <th>mult</th>\n",
       "      <th>add</th>\n",
       "      <th>relBeg</th>\n",
       "      <th>...</th>\n",
       "      <th>nextV</th>\n",
       "      <th>next2</th>\n",
       "      <th>nextBi</th>\n",
       "      <th>prevBi</th>\n",
       "      <th>curBi</th>\n",
       "      <th>prevTri</th>\n",
       "      <th>curTri</th>\n",
       "      <th>nextTri</th>\n",
       "      <th>curQuat</th>\n",
       "      <th>bound</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>28336</th>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.885390</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>$</td>\n",
       "      <td>i$</td>\n",
       "      <td>^r</td>\n",
       "      <td>ri</td>\n",
       "      <td>^ri</td>\n",
       "      <td>ri$</td>\n",
       "      <td>i$$</td>\n",
       "      <td>^ri$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28337</th>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.106675</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>p</td>\n",
       "      <td>up</td>\n",
       "      <td>^n</td>\n",
       "      <td>nu</td>\n",
       "      <td>^nu</td>\n",
       "      <td>nup</td>\n",
       "      <td>upa</td>\n",
       "      <td>^nup</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28338</th>\n",
       "      <td>2</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.569492</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>a</td>\n",
       "      <td>pa</td>\n",
       "      <td>nu</td>\n",
       "      <td>up</td>\n",
       "      <td>nup</td>\n",
       "      <td>upa</td>\n",
       "      <td>pam</td>\n",
       "      <td>nupa</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28339</th>\n",
       "      <td>3</td>\n",
       "      <td>p</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.569492</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>m</td>\n",
       "      <td>am</td>\n",
       "      <td>up</td>\n",
       "      <td>pa</td>\n",
       "      <td>upa</td>\n",
       "      <td>pam</td>\n",
       "      <td>am$</td>\n",
       "      <td>upam</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28340</th>\n",
       "      <td>4</td>\n",
       "      <td>a</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.106675</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>$</td>\n",
       "      <td>m$</td>\n",
       "      <td>pa</td>\n",
       "      <td>am</td>\n",
       "      <td>pam</td>\n",
       "      <td>am$</td>\n",
       "      <td>m$$</td>\n",
       "      <td>pam$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28341</th>\n",
       "      <td>1</td>\n",
       "      <td>X</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>5</td>\n",
       "      <td>6</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.348664</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>n</td>\n",
       "      <td>in</td>\n",
       "      <td>^X</td>\n",
       "      <td>Xi</td>\n",
       "      <td>^Xi</td>\n",
       "      <td>Xin</td>\n",
       "      <td>inb</td>\n",
       "      <td>^Xin</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28342</th>\n",
       "      <td>2</td>\n",
       "      <td>i</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>4</td>\n",
       "      <td>6</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.730718</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>b</td>\n",
       "      <td>nb</td>\n",
       "      <td>Xi</td>\n",
       "      <td>in</td>\n",
       "      <td>Xin</td>\n",
       "      <td>inb</td>\n",
       "      <td>nbʼ</td>\n",
       "      <td>Xinb</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28343</th>\n",
       "      <td>3</td>\n",
       "      <td>n</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>6</td>\n",
       "      <td>2.302585</td>\n",
       "      <td>2.605767</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>0</td>\n",
       "      <td>ʼ</td>\n",
       "      <td>bʼ</td>\n",
       "      <td>in</td>\n",
       "      <td>nb</td>\n",
       "      <td>inb</td>\n",
       "      <td>nbʼ</td>\n",
       "      <td>bʼe</td>\n",
       "      <td>inbʼ</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28344</th>\n",
       "      <td>4</td>\n",
       "      <td>b</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>6</td>\n",
       "      <td>2.197225</td>\n",
       "      <td>2.730718</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>e</td>\n",
       "      <td>ʼe</td>\n",
       "      <td>nb</td>\n",
       "      <td>bʼ</td>\n",
       "      <td>nbʼ</td>\n",
       "      <td>bʼe</td>\n",
       "      <td>ʼe$</td>\n",
       "      <td>nbʼe</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>28345</th>\n",
       "      <td>5</td>\n",
       "      <td>ʼ</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>6</td>\n",
       "      <td>1.791759</td>\n",
       "      <td>3.348664</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>...</td>\n",
       "      <td>1</td>\n",
       "      <td>$</td>\n",
       "      <td>e$</td>\n",
       "      <td>bʼ</td>\n",
       "      <td>ʼe</td>\n",
       "      <td>bʼe</td>\n",
       "      <td>ʼe$</td>\n",
       "      <td>e$$</td>\n",
       "      <td>bʼe$</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>10 rows × 26 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "       beg sym  vow  vel  pos  end  len      mult       add    relBeg  ...  \\\n",
       "28336    1   r    0    0    1    1    2  0.693147  2.885390  0.500000  ...   \n",
       "28337    1   n    0    0    2    4    5  1.609438  3.106675  0.200000  ...   \n",
       "28338    2   u    1    0    2    3    5  1.945910  2.569492  0.400000  ...   \n",
       "28339    3   p    0    0    2    2    5  1.945910  2.569492  0.600000  ...   \n",
       "28340    4   a    1    0    2    1    5  1.609438  3.106675  0.800000  ...   \n",
       "28341    1   X    0    0    0    5    6  1.791759  3.348664  0.166667  ...   \n",
       "28342    2   i    1    0    0    4    6  2.197225  2.730718  0.333333  ...   \n",
       "28343    3   n    0    0    0    3    6  2.302585  2.605767  0.500000  ...   \n",
       "28344    4   b    0    0    0    2    6  2.197225  2.730718  0.666667  ...   \n",
       "28345    5   ʼ    1    0    0    1    6  1.791759  3.348664  0.833333  ...   \n",
       "\n",
       "       nextV  next2  nextBi prevBi  curBi prevTri  curTri nextTri curQuat  \\\n",
       "28336      1      $      i$     ^r     ri     ^ri     ri$     i$$    ^ri$   \n",
       "28337      1      p      up     ^n     nu     ^nu     nup     upa    ^nup   \n",
       "28338      0      a      pa     nu     up     nup     upa     pam    nupa   \n",
       "28339      1      m      am     up     pa     upa     pam     am$    upam   \n",
       "28340      0      $      m$     pa     am     pam     am$     m$$    pam$   \n",
       "28341      1      n      in     ^X     Xi     ^Xi     Xin     inb    ^Xin   \n",
       "28342      0      b      nb     Xi     in     Xin     inb     nbʼ    Xinb   \n",
       "28343      0      ʼ      bʼ     in     nb     inb     nbʼ     bʼe    inbʼ   \n",
       "28344      1      e      ʼe     nb     bʼ     nbʼ     bʼe     ʼe$    nbʼe   \n",
       "28345      1      $      e$     bʼ     ʼe     bʼe     ʼe$     e$$    bʼe$   \n",
       "\n",
       "      bound  \n",
       "28336     0  \n",
       "28337     0  \n",
       "28338     1  \n",
       "28339     0  \n",
       "28340     0  \n",
       "28341     1  \n",
       "28342     0  \n",
       "28343     1  \n",
       "28344     0  \n",
       "28345     0  \n",
       "\n",
       "[10 rows x 26 columns]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "neues.tail(10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "oneh = OneHotEncoder()\n",
    "temp = neues.iloc[:,:-1]\n",
    "common = pd.concat([temp, all_tst], axis=0)\n",
    "oneh.fit(common[[\"sym\", \"prev\", \"next\", \\\n",
    "                 \"next2\", \"nextBi\", \"nextTri\", \\\n",
    "                 \"prevBi\", \"curBi\", \"prevTri\", \\\n",
    "                 \"curTri\", \"curQuat\"]])\n",
    "\n",
    "trans = oneh.transform(neues[[\"sym\", \"prev\", \"next\", \\\n",
    "                              \"next2\", \"nextBi\", \"nextTri\", \\\n",
    "                              \"prevBi\", \"curBi\", \"prevTri\", \\\n",
    "                              \"curTri\", \"curQuat\"]])\n",
    "\n",
    "tr_test = oneh.transform(all_tst[[\"sym\", \"prev\", \"next\", \\\n",
    "                                  \"next2\", \"nextBi\", \"nextTri\", \\\n",
    "                                  \"prevBi\", \"curBi\", \"prevTri\", \\\n",
    "                                  \"curTri\", \"curQuat\"]])\n",
    "\n",
    "coo1 = coo_matrix(neues[[\"beg\", \"end\", \"len\", \\\n",
    "                         \"vow\", \"vel\", \"pos\", \\\n",
    "                         \"mult\", \"relBeg\", \"relEnd\", \\\n",
    "                         \"logBeg\", \"logEnd\", \"add\"]].to_numpy())\n",
    "\n",
    "coo2 = coo_matrix(all_tst[[\"beg\", \"end\", \"len\", \\\n",
    "                           \"vow\", \"vel\", \"pos\", \\\n",
    "                           \"mult\", \"relBeg\", \"relEnd\", \\\n",
    "                           \"logBeg\", \"logEnd\", \"add\"]].to_numpy())\n",
    "\n",
    "alles = hstack([coo1, trans])\n",
    "tst_matrix = hstack([coo2, tr_test])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = neues[\"bound\"].to_numpy(dtype=np.dtype(int))\n",
    "x_train, x_test, y_train, y_test = train_test_split(alles, y, test_size=0.10)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=1, class_weight='balanced', max_iter=150, n_jobs=2)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logreg = LogisticRegression(C=1, class_weight=\"balanced\", max_iter=150, n_jobs=2)\n",
    "logreg.fit(x_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 492,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_pred = logreg.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 493,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "    no_bound       0.98      0.95      0.97      2356\n",
      "    is_bound       0.79      0.93      0.85       479\n",
      "\n",
      "    accuracy                           0.95      2835\n",
      "   macro avg       0.89      0.94      0.91      2835\n",
      "weighted avg       0.95      0.95      0.95      2835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "target_names = [\"no_bound\", \"is_bound\"]\n",
    "print(classification_report(y_test, y_pred, target_names=target_names))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 465,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('fit_time', array([2.12908387, 0.96810913, 0.94753456, 0.93192744, 0.92413592]))\n",
      "\n",
      "('score_time', array([0.00700307, 0.00499964, 0.00500226, 0.00500131, 0.00499988]))\n",
      "\n",
      "('test_f1', array([0.86218735, 0.86550868, 0.8641604 , 0.85928144, 0.85121107]))\n",
      "\n",
      "('test_f1_weighted', array([0.95206347, 0.95358159, 0.95339283, 0.95158131, 0.94849653]))\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scores = cross_validate(logreg, alles, y, cv=5, scoring=(\"f1\", \"f1_weighted\"), return_train_score=False)\n",
    "for i in scores.items():\n",
    "    print(str(i) + \"\\n\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 466,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAXIAAAD4CAYAAADxeG0DAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADh0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uMy4yLjIsIGh0dHA6Ly9tYXRwbG90bGliLm9yZy+WH4yJAAAP1ElEQVR4nO3dfaxkdX3H8c+ne0Es0iLltqwsy4VITIgxYCdGStMHoO0KBGOrCaQojTabpmmCbRNhs0kb0zTB0hjT0JRukNZUClqFQhYJDyoxJhWcVaSLyypW1K20O8bUh5q0bvn2jzkXhrvzfH4zc74z71cyuTPn4Xe+5+lzzpw5c8cRIQBAXj+x6AIAAPUQ5ACQHEEOAMkR5ACQHEEOAMmtLWKip59+emxsbCxi0gCQ1oEDB74TEetbuy8kyDc2NtRutxcxaQBIy/Y3+nXn0goAJEeQA0ByBDkAJEeQA0ByBDkAJEeQA0ByBDkAJEeQA0ByBDkAJFcsyG1vs/1F2/tLtQkAGK3kGfn1kg4VbA8AMIYiQW57h6QrJN1Woj0AwPhKnZF/QNJ7JD0/aADbu223bbc7nU6hyQIAage57SslHY2IA8OGi4h9EdGKiNb6+nH/hREAMKUSZ+QXS7rK9rOS7pJ0ie0PF2gXADCG2kEeEXsiYkdEbEi6WtKnIuLa2pUBAMbCfeQAkFzRXwiKiEclPVqyTQDAcJyRA0ByBDkAJEeQA0ByBDkAJEeQA0ByBDkAJEeQA0ByBDkAJEeQA0ByBDkAJEeQA0ByBDkAJEeQA0ByBDkAJEeQA0ByBDkAJEeQA0ByBDkAJEeQA0BytYPc9km2H7f9JdtP2X5vicIAAOMp8ePL/yPpkoj4oe0TJH3W9gMR8bkCbQMARqgd5BERkn5YvTyhekTddgEA4ylyjdz2NttPSDoq6eGIeKzPMLttt223O51OickCAFQoyCPi/yLiAkk7JL3B9mv7DLMvIloR0VpfXy8xWQCACt+1EhH/JelRSbtKtgsAGKzEXSvrtk+tnr9c0mWSnq7bLgBgPCXuWtku6UO2t6l7YPhoROwv0C4AYAwl7lp5UtKFBWoBAEyBb3YCQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkVzvIbZ9l+9O2D9l+yvb1JQoDAIxnrUAbxyT9cUR8wfYpkg7YfjgivlygbQDACLXPyCPiuYj4QvX8B5IOSTqzbrsAgPEUvUZue0PShZIe69Nvt+227Xan0yk5WQBYacWC3PYrJH1c0rsj4vtb+0fEvohoRURrfX291GQBYOUVCXLbJ6gb4ndExN0l2gQAjKfEXSuW9EFJhyLi/fVLAgBMosQZ+cWS3i7pEttPVI/LC7QLABhD7dsPI+KzklygFgDAFPhmJwAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEOQAkR5ADQHIEeWEbN96/6BIArBiCHACSI8gBIDmCHACSI8gBILkiQW77dttHbR8s0R4AYHylzsj/XtKuQm0BACZQJMgj4jOSvluiLQDAZOZ2jdz2bttt2+1OpzOvyQLA0ptbkEfEvohoRURrfX19XpMFgKW30net8C3M6bHsgOZY6SAHgGVQ6vbDOyX9i6TX2D5i+10l2gUAjLZWopGIuKZEOwCAyXFpBY3FdXhgPAQ5ACRHkANAcgQ5ilimyyDLNC9YDQQ5UBgHAswbQQ4AU2jSAZsgH6JJKwqzUWodL+O2UmKelnG5NBFBDgDJEeQAkBxBvsW4bwXHGY63lSwDLN4qbIMEeUOtwsa3bFhnyyHjeiTIgQXbDI6MAYJmWOogX+Udo9+8r/LyaBLWA0pb6iCfFjsalhHb9fIiyBuOnW+5LMP6XIZ5WDYEOVYOQbT8Vm0dE+RLZtU2YKApFrnvEeRoPA5OwHBLG+Ts/BhmVbePJvxvmVVd9rNU6seXd9k+bPsZ2zeWaBPNws43PZbdYCybMmoHue1tkv5a0psknS/pGtvn1203u0VsoE3ZKVZ53jc1rR4stxJn5G+Q9ExE/FtE/K+kuyS9uUC7AAYYdaDgQLJiIqLWQ9JbJd3W8/rtkm7pM9xuSW1J7Z07d8a0zr5hf5x9w/6Rz3uH7/d3a3u94w9qY9B0+o0/ahqj5mFY+/3qGTbesGXSb9xh9Qyah0HzPWz+J2273/iTLNNR63jU+hvVXr82+z0fNI1B3YbVOUm/UfPTb5qD9o+tdQ5ro98w/aYxzvNR29Kw56NqG2cfGratjZq3rdOdhqR29MnhEmfk7nd86HPA2BcRrYhora+vTz2xZ2+6YujrQcNv/bt1mFHtjJrmJONvrWeccSdtf+s4dcfv133SZT9q2FHLYpz+w6Y36XoeNN64624W29SwaY7qN+h1nWU+zrQmGX7a9Tvptj5offbrNmrYUe3PQ4kgPyLprJ7XOyR9u0C76ZReebPaGOq0W+IgNk9Nrm1cs5yHebVd+oAwq5OfWZhHHSWC/POSzrN9ju0TJV0t6b4C7Q40yZneuG1NM/ykdZQ6gyu5Ycx7Yy+9M5eqvyk7/aSm2Z6mCcFS7zzmbdz5yHRg6GetbgMRccz2H0h6UNI2SbdHxFO1K2uQJq/AOpoe4uO2tephPi9Z3xnMWt1LaCXUDnJJiohPSPpEibZwvFlfo1x0u7OQqVaMb9r1uuzbw1J+s3PZV9osLeNBYJ7TZtubP5b5kgZ50zR9Q2t6fVhOk1yXbuo22pS6CHI0UlN2EIyH9bVYBPmcsKED41mmfWVe87JUQV53oWXcgEp+KQXIhG37RUsV5ACwipYmyDk6Yx7YztBESxPkpS1qh21aUDStHgDHI8gBIDmCHACSI8ixEFyyAcohyIE54MA1H6u6nAnyRFZ1IwUwHEG+JAh5YHUR5FhZHPywLAhyAEiOIMdxOFMFciHIASA5ghzAC3g3lhNBDgDJ1Qpy22+z/ZTt5223ShUFABhf3TPyg5J+U9JnCtQCAJjCWp2RI+KQJNkuUw0AYGJzu0Zue7fttu12p9OZ12QBYOmNPCO3/YikM/r02hsR9447oYjYJ2mfJLVarRi7QgDAUCODPCIum0chAIDpcPshACRX9/bDt9g+IukiSffbfrBMWQCAcdW9a+UeSfcUqgUAMAUurQBAcgQ5ACRHkANAcgQ5ACRHkANAcgQ5ACRHkANAcgQ5ACRHkANAcgQ5ACRHkANAcgQ5ACRHkGNhnr3pikWXACwFghwAkiPIASA5ghwAkiPIASA5ghwAkiPIASC5uj++fLPtp20/afse26eWKgwAMJ66Z+QPS3ptRLxO0lck7alfEgBgErWCPCIeiohj1cvPSdpRvyQAwCRKXiN/p6QHBvW0vdt223a70+kUnCwArLa1UQPYfkTSGX167Y2Ie6th9ko6JumOQe1ExD5J+ySp1WrFVNUCAI4zMsgj4rJh/W1fJ+lKSZdGBAENAHM2MsiHsb1L0g2SfjkiflSmJADAJOpeI79F0imSHrb9hO1bC9QEAJhArTPyiHh1qUIAANPhm50AkBxBDgDJEeQAkBxBDgDJEeQAkBxBDgDJEeQAkBxBDgDJEeQAkBxBDgDJEeQAkBxBDgDJEeQAkBxBDgDJEeQAkBxBDgDJEeQAkBxBDgDJEeQAkFytILf9Z7afrH54+SHbrypVGABgPHXPyG+OiNdFxAWS9kv6kwI1AQAmUCvII+L7PS9PlhT1ygEATGqtbgO2/1zSOyR9T9KvDhlut6TdkrRz5866kwUAVBwx/CTa9iOSzujTa29E3Nsz3B5JJ0XEn46aaKvVina7PWmtALDSbB+IiNbW7iPPyCPisjGn8Y+S7pc0MsgBAOXUvWvlvJ6XV0l6ul45AIBJ1b1GfpPt10h6XtI3JP1e/ZIAAJOoFeQR8VulCgEATGfkh50zmajdUfcMfhqnS/pOwXLmJWvdUt7aqXu+qHv2zo6I9a0dFxLkddhu9/vUtumy1i3lrZ2654u6F4f/tQIAyRHkAJBcxiDft+gCppS1bilv7dQ9X9S9IOmukQMAXirjGTkAoAdBDgDJpQpy27tsH7b9jO0bF1zLWbY/bfuQ7adsX191P832w7a/Wv19Zc84e6raD9v+jZ7uP2/7X6t+f2Xbc6h/m+0v2t6frO5TbX/M9tPVsr8oQ+22/7DaTg7avtP2SU2s2/btto/aPtjTrVidtl9m+yNV98dsb8yw7pur7eRJ2/fYPrVpdRcTESkekrZJ+pqkcyWdKOlLks5fYD3bJb2+en6KpK9IOl/SX0i6sep+o6T3Vc/Pr2p+maRzqnnZVvV7XNJFkizpAUlvmkP9f6TuPzrbX73OUveHJP1u9fxESac2vXZJZ0r6uqSXV68/Kul3mli3pF+S9HpJB3u6FatT0u9LurV6frWkj8yw7l+XtFY9f18T6y623hZdwAQr6iJJD/a83iNpz6Lr6qnnXkm/JumwpO1Vt+2SDverV9KD1Txtl/R0T/drJP3tjGvdIemTki7Ri0Geoe6fUjcQvaV7o2tXN8i/Jek0df8txv4qZBpZt6SNLYFYrM7NYarna+p+o9KzqHtLv7dIuqOJdZd4ZLq0srkzbDpSdVu46m3WhZIek/RzEfGcJFV/f7YabFD9Z1bPt3afpQ9Ieo+6/+xsU4a6z5XUkfR31WWh22yf3PTaI+LfJf2lpG9Kek7S9yLioabX3aNknS+MExHH1P1Bmp+ZWeUveqe6Z9gvqWFLfU2seyyZgrzftcCF3ztp+xWSPi7p3fHSn747btA+3WJI95mwfaWkoxFxYNxR+nSbe92VNXXfPv9NRFwo6b/Vfas/SCNqr64pv1ndt/GvknSy7WuHjdKn26KW+TDT1Dn3ebC9V9IxSXeMqKFRdU8iU5AfkXRWz+sdkr69oFokSbZPUDfE74iIu6vO/2l7e9V/u6SjVfdB9R+pnm/tPisXS7rK9rOS7pJ0ie0PJ6h7s5YjEfFY9fpj6gZ702u/TNLXI6ITET+WdLekX0hQ96aSdb4wju01ST8t6buzKtz2dZKulPTbUV0XyVD3pDIF+eclnWf7HNsnqvuBw32LKqb6NPuDkg5FxPt7et0n6brq+XXqXjvf7H519en3OZLOk/R49Vb1B7bfWLX5jp5xiouIPRGxIyI21F2Gn4qIa5ted1X7f0j6lrv/A1+SLpX05QS1f1PSG23/ZDW9SyUdSlD3ppJ19rb1VnW3v5mc2dreJekGSVdFxI+2zE9j657Koi/ST/KQdLm6d4d8Td3fDF1kLb+o7lurJyU9UT0uV/e62SclfbX6e1rPOHur2g+r524DSS1JB6t+t2hOH6JI+hW9+GFnirolXSCpXS33f5b0ygy1S3qvur+gdVDSP6h7x0Tj6pZ0p7rX8X+s7lnou0rWKekkSf8k6Rl17xA5d4Z1P6Pude3N/fPWptVd6sFX9AEguUyXVgAAfRDkAJAcQQ4AyRHkAJAcQQ4AyRHkAJAcQQ4Ayf0/EdGIKKCx7aEAAAAASUVORK5CYII=\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "importance = logreg.coef_\n",
    "plt.bar([x for x in range(len(importance[0]))], importance[0])\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 531,
   "metadata": {},
   "outputs": [],
   "source": [
    "def process_string(inp: str, encoder: object, model: object):\n",
    "    \"\"\"return the predicted version of the string\n",
    "    :param inp: string to process\n",
    "    :param encoder: one-hot encoder conditioned on the training set\n",
    "    :param model: a linear regression model conditioned on the training set\n",
    "    \n",
    "    >>> process_string(\"acab\")\n",
    "    \"ac>ab\"\n",
    "    \"\"\"\n",
    "    if not type(inp) == str:\n",
    "        raise TypeError(\"only accepts strings as input\")\n",
    "    delimiters = re.findall(r\"( [a-bA-B][.,?:\\- ]+|[^a-zA-Zʼ]+)\", inp)\n",
    "    inp_new = \"^\" + re.sub(\" \", \"$ ^\", inp) + \"$\"\n",
    "    inp_list = [inp_new.split(\" \")]\n",
    "    inp_stats = preprocess(inp_list)\n",
    "    stats_df = pd.DataFrame.from_dict(to_sound_list(inp_stats))\n",
    "    discrete = encoder.transform(stats_df[[\"sym\", \"prev\", \"next\", \\\n",
    "                              \"next2\", \"nextBi\", \"nextTri\", \\\n",
    "                              \"prevBi\", \"curBi\", \"prevTri\", \\\n",
    "                              \"curTri\", \"curQuat\"]])\n",
    "    numeric = coo_matrix(stats_df[[\"beg\", \"end\", \"len\", \\\n",
    "                         \"vow\", \"vel\", \"pos\", \\\n",
    "                         \"mult\", \"relBeg\", \"relEnd\", \\\n",
    "                         \"logBeg\", \"logEnd\", \"add\"]].to_numpy())\n",
    "    features = hstack([numeric, discrete])\n",
    "    labels = model.predict(features)\n",
    "    reusable_line = \"\"\n",
    "    output_list = []\n",
    "    for ind in range(labels.shape[0]):\n",
    "        line = stats_df.loc[ind, [\"sym\", \"next\", \"nextBi\"]]\n",
    "        reusable_line += line[\"sym\"]\n",
    "        if labels[ind] == 1:\n",
    "            reusable_line += \">\"\n",
    "        if \"$\" in line[\"nextBi\"]:\n",
    "            reusable_line += line[\"next\"]\n",
    "            output_list.append(reusable_line)\n",
    "            reusable_line = \"\"\n",
    "    if len(output_list) == 1 or len(delimiters) == 0:\n",
    "        return output_list[0]\n",
    "    if len(output_list) != len(delimiters):\n",
    "        raise Exception(\"inconsistent number of words and delimiters\")\n",
    "    output_list[-1] += delimiters[-1]\n",
    "    output_string = \"\"\n",
    "    for index in range(len(delimiters))[:-1]:\n",
    "        output_string += output_list[index]\n",
    "        output_string += delimiters[index]\n",
    "    output_string += output_list[-1]\n",
    "    return output_string"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 532,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Chi u>xeʼ ri mexa kʼo wi ri chʼo .'"
      ]
     },
     "execution_count": 532,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "process_string(\"Chi uxeʼ ri mexa kʼo wi ri chʼo .\", oneh, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 533,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserve = dev.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 534,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Chi uxeʼ ri mexa kʼo wi ri chʼo .\n",
      "Na xinnabʼej ta chutasik qakʼolibʼal .\n",
      "Xubʼij che : - jas xabʼano Tintin ?\n",
      "Chanim in kʼo pa mokokil .\n",
      "Xalax pa ri Kaweq .\n",
      "Xpax ri ujukubʼ , ri kej .\n",
      "Je la leʼ ri nupwiʼ .\n",
      "Kʼo pa ja tijobʼal ri wikaqʼ .\n",
      "Xinalax pa jun qʼij ubʼiʼ wajxaqibʼ Noʼj .\n",
      "Aʼre xetoʼw alaq .\n",
      "Aʼre xetoʼw alaq .\n",
      "Xintik qʼax chi uwach ri ja .\n",
      "Aninaq kwaj ri nuwa .\n",
      "Xqarqat ri akʼ are chiʼ xsikʼowik .\n",
      "Karapinik xutzukuj chi jun awaj .\n",
      "Oj kʼo pa le roʼch le a Wel .\n",
      "We man je kabʼan chike , kabʼison le rajaw tuj .\n",
      "Xnaʼtaj ri akʼal chwe .\n",
      "Kawaj kimbʼe pa tinamit .\n",
      "Chaqiʼj chik ri chaj .\n",
      "Xinloqʼ jun kʼakʼ ukaʼ ri numiʼal .\n",
      "Jawi kʼo wi le wuj re le qatijonik ?\n",
      "Noʼjim ukemik le pas awumal .\n",
      "Noʼjim ukemik le pas awumal .\n",
      "Nim ubʼaqʼ ri tulul .\n"
     ]
    }
   ],
   "source": [
    "for index, line in enumerate(reserve[0]):\n",
    "    print(line)\n",
    "    reserve.iloc[index, 1] = process_string(line, oneh, logreg)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 537,
   "metadata": {},
   "outputs": [],
   "source": [
    "reserve.to_csv(\"out.tsv\", sep=\"\\t\", header=False, index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 482,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>beg</th>\n",
       "      <th>sym</th>\n",
       "      <th>vow</th>\n",
       "      <th>vel</th>\n",
       "      <th>pos</th>\n",
       "      <th>end</th>\n",
       "      <th>len</th>\n",
       "      <th>mult</th>\n",
       "      <th>add</th>\n",
       "      <th>relBeg</th>\n",
       "      <th>...</th>\n",
       "      <th>next</th>\n",
       "      <th>nextV</th>\n",
       "      <th>next2</th>\n",
       "      <th>nextBi</th>\n",
       "      <th>prevBi</th>\n",
       "      <th>curBi</th>\n",
       "      <th>prevTri</th>\n",
       "      <th>curTri</th>\n",
       "      <th>nextTri</th>\n",
       "      <th>curQuat</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>C</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.730718</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>...</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>i</td>\n",
       "      <td>hi</td>\n",
       "      <td>^C</td>\n",
       "      <td>Ch</td>\n",
       "      <td>^Ch</td>\n",
       "      <td>Chi</td>\n",
       "      <td>hi$</td>\n",
       "      <td>^Chi</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>2</td>\n",
       "      <td>h</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>1.098612</td>\n",
       "      <td>2.730718</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>...</td>\n",
       "      <td>i</td>\n",
       "      <td>1</td>\n",
       "      <td>$</td>\n",
       "      <td>i$</td>\n",
       "      <td>Ch</td>\n",
       "      <td>hi</td>\n",
       "      <td>Chi</td>\n",
       "      <td>hi$</td>\n",
       "      <td>i$$</td>\n",
       "      <td>Chi$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.885390</td>\n",
       "      <td>0.250000</td>\n",
       "      <td>...</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>e</td>\n",
       "      <td>xe</td>\n",
       "      <td>^u</td>\n",
       "      <td>ux</td>\n",
       "      <td>^ux</td>\n",
       "      <td>uxe</td>\n",
       "      <td>xeʼ</td>\n",
       "      <td>^uxe</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>2</td>\n",
       "      <td>x</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>4</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>2.485340</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>ʼ</td>\n",
       "      <td>eʼ</td>\n",
       "      <td>ux</td>\n",
       "      <td>xe</td>\n",
       "      <td>uxe</td>\n",
       "      <td>xeʼ</td>\n",
       "      <td>eʼ$</td>\n",
       "      <td>uxeʼ</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>3</td>\n",
       "      <td>e</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>1</td>\n",
       "      <td>1</td>\n",
       "      <td>4</td>\n",
       "      <td>1.386294</td>\n",
       "      <td>2.885390</td>\n",
       "      <td>0.750000</td>\n",
       "      <td>...</td>\n",
       "      <td>ʼ</td>\n",
       "      <td>1</td>\n",
       "      <td>$</td>\n",
       "      <td>ʼ$</td>\n",
       "      <td>xe</td>\n",
       "      <td>eʼ</td>\n",
       "      <td>xeʼ</td>\n",
       "      <td>eʼ$</td>\n",
       "      <td>ʼ$$</td>\n",
       "      <td>xeʼ$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>415</th>\n",
       "      <td>1</td>\n",
       "      <td>r</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>2</td>\n",
       "      <td>1</td>\n",
       "      <td>2</td>\n",
       "      <td>0.693147</td>\n",
       "      <td>2.885390</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>...</td>\n",
       "      <td>i</td>\n",
       "      <td>1</td>\n",
       "      <td>$</td>\n",
       "      <td>i$</td>\n",
       "      <td>^r</td>\n",
       "      <td>ri</td>\n",
       "      <td>^ri</td>\n",
       "      <td>ri$</td>\n",
       "      <td>i$$</td>\n",
       "      <td>^ri$</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>416</th>\n",
       "      <td>1</td>\n",
       "      <td>t</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>4</td>\n",
       "      <td>5</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.106675</td>\n",
       "      <td>0.200000</td>\n",
       "      <td>...</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>l</td>\n",
       "      <td>ul</td>\n",
       "      <td>^t</td>\n",
       "      <td>tu</td>\n",
       "      <td>^tu</td>\n",
       "      <td>tul</td>\n",
       "      <td>ulu</td>\n",
       "      <td>^tul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>417</th>\n",
       "      <td>2</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>3</td>\n",
       "      <td>5</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.569492</td>\n",
       "      <td>0.400000</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>0</td>\n",
       "      <td>u</td>\n",
       "      <td>lu</td>\n",
       "      <td>tu</td>\n",
       "      <td>ul</td>\n",
       "      <td>tul</td>\n",
       "      <td>ulu</td>\n",
       "      <td>lul</td>\n",
       "      <td>tulu</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>418</th>\n",
       "      <td>3</td>\n",
       "      <td>l</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>2</td>\n",
       "      <td>5</td>\n",
       "      <td>1.945910</td>\n",
       "      <td>2.569492</td>\n",
       "      <td>0.600000</td>\n",
       "      <td>...</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>l</td>\n",
       "      <td>ul</td>\n",
       "      <td>ul</td>\n",
       "      <td>lu</td>\n",
       "      <td>ulu</td>\n",
       "      <td>lul</td>\n",
       "      <td>ul$</td>\n",
       "      <td>ulul</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>419</th>\n",
       "      <td>4</td>\n",
       "      <td>u</td>\n",
       "      <td>1</td>\n",
       "      <td>0</td>\n",
       "      <td>3</td>\n",
       "      <td>1</td>\n",
       "      <td>5</td>\n",
       "      <td>1.609438</td>\n",
       "      <td>3.106675</td>\n",
       "      <td>0.800000</td>\n",
       "      <td>...</td>\n",
       "      <td>l</td>\n",
       "      <td>0</td>\n",
       "      <td>$</td>\n",
       "      <td>l$</td>\n",
       "      <td>lu</td>\n",
       "      <td>ul</td>\n",
       "      <td>lul</td>\n",
       "      <td>ul$</td>\n",
       "      <td>l$$</td>\n",
       "      <td>lul$</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>420 rows × 25 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     beg sym  vow  vel  pos  end  len      mult       add    relBeg  ...  \\\n",
       "0      1   C    0    0    0    2    3  1.098612  2.730718  0.333333  ...   \n",
       "1      2   h    0    0    0    1    3  1.098612  2.730718  0.666667  ...   \n",
       "2      1   u    1    0    1    3    4  1.386294  2.885390  0.250000  ...   \n",
       "3      2   x    0    1    1    2    4  1.609438  2.485340  0.500000  ...   \n",
       "4      3   e    1    0    1    1    4  1.386294  2.885390  0.750000  ...   \n",
       "..   ...  ..  ...  ...  ...  ...  ...       ...       ...       ...  ...   \n",
       "415    1   r    0    0    2    1    2  0.693147  2.885390  0.500000  ...   \n",
       "416    1   t    0    0    3    4    5  1.609438  3.106675  0.200000  ...   \n",
       "417    2   u    1    0    3    3    5  1.945910  2.569492  0.400000  ...   \n",
       "418    3   l    0    0    3    2    5  1.945910  2.569492  0.600000  ...   \n",
       "419    4   u    1    0    3    1    5  1.609438  3.106675  0.800000  ...   \n",
       "\n",
       "     next  nextV  next2 nextBi  prevBi curBi  prevTri curTri nextTri curQuat  \n",
       "0       h      0      i     hi      ^C    Ch      ^Ch    Chi     hi$    ^Chi  \n",
       "1       i      1      $     i$      Ch    hi      Chi    hi$     i$$    Chi$  \n",
       "2       x      0      e     xe      ^u    ux      ^ux    uxe     xeʼ    ^uxe  \n",
       "3       e      1      ʼ     eʼ      ux    xe      uxe    xeʼ     eʼ$    uxeʼ  \n",
       "4       ʼ      1      $     ʼ$      xe    eʼ      xeʼ    eʼ$     ʼ$$    xeʼ$  \n",
       "..    ...    ...    ...    ...     ...   ...      ...    ...     ...     ...  \n",
       "415     i      1      $     i$      ^r    ri      ^ri    ri$     i$$    ^ri$  \n",
       "416     u      1      l     ul      ^t    tu      ^tu    tul     ulu    ^tul  \n",
       "417     l      0      u     lu      tu    ul      tul    ulu     lul    tulu  \n",
       "418     u      1      l     ul      ul    lu      ulu    lul     ul$    ulul  \n",
       "419     l      0      $     l$      lu    ul      lul    ul$     l$$    lul$  \n",
       "\n",
       "[420 rows x 25 columns]"
      ]
     },
     "execution_count": 482,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "all_tst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 467,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred = logreg.predict(tst_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# tst_string = str()\n",
    "# for ind in range(pred.shape[0]):\n",
    "#     line = all_tst.loc[ind, [\"sym\", \"next\", \"nextBi\"]]\n",
    "#     tst_string += line[\"sym\"]\n",
    "#     if pred[ind] == 1:\n",
    "#         tst_string += \">\"\n",
    "#     if \"$\" in line[\"nextBi\"]:\n",
    "#         tst_string += (line[\"next\"] + \"\\n\")\n",
    "# print(tst_string)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 269,
   "metadata": {},
   "outputs": [],
   "source": [
    "# sym_stats = []\n",
    "# vowels = {\"u\", \"i\", \"a\", \"o\", \"e\", \"ʼ\"}\n",
    "# velar = {\"k\", \"x\", \"q\"}\n",
    "# for sent in words_1:\n",
    "#     snt = []\n",
    "# #     for word in sent:\n",
    "#     for index in range(len(sent)):\n",
    "#         word = sent[index]\n",
    "#         true_len = len(word) - 2\n",
    "#         if true_len <= 1:\n",
    "#             continue\n",
    "#         wrd = []\n",
    "#         num_vow = len(re.findall(r\"[aouei]\", word))\n",
    "#         for i in range(len(word))[1:len(word)-2]:\n",
    "#             dic = {}\n",
    "#             dic[\"sym\"]=word[i]\n",
    "#             dic[\"beg\"]=i\n",
    "#             if dic[\"sym\"] in vowels:\n",
    "#                 dic[\"vow\"] = 1\n",
    "#             else:\n",
    "#                 dic[\"vow\"] = 0\n",
    "#             if dic[\"sym\"] in velar:\n",
    "#                 dic[\"vel\"] = 1\n",
    "#             else:\n",
    "#                 dic[\"vel\"] = 0\n",
    "#             dic[\"pos\"] = index\n",
    "#             dic[\"end\"]=true_len - dic[\"beg\"]\n",
    "#             dic[\"len\"]= true_len\n",
    "#             dic[\"nSyl\"]=num_vow\n",
    "#             dic[\"prev\"]=word[i-1]\n",
    "#             if dic[\"prev\"] in vowels:\n",
    "#                 dic[\"prevV\"] = 1\n",
    "#             else:\n",
    "#                 dic[\"prevV\"] = 0\n",
    "#             dic[\"next\"]=word[i+1]\n",
    "#             if dic[\"next\"] in vowels:\n",
    "#                 dic[\"nextV\"] = 1\n",
    "#             else:\n",
    "#                 dic[\"nextV\"] = 0\n",
    "#             dic[\"next2\"]=word[i+2]\n",
    "#             dic[\"nextBi\"]=dic[\"next\"] + dic[\"next2\"]\n",
    "#             wrd.append(dic)\n",
    "#         snt.append(wrd)\n",
    "#     sym_stats.append(snt)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
